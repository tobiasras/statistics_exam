{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "from cgi import print_form\n",
    "from os import error\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# exam set June 2024",
   "id": "ccee3f8ac3289a38"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### poisson distribution",
   "id": "8cc479e3d637fc13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#task 1\n",
    "lambda1 = 10 #every hour\n",
    "lambda2 = 15 #every hour\n",
    "\n",
    "lambda1New = lambda1/4\n",
    "lambda2New = lambda2/6\n",
    "\n",
    "print(stats.poisson.pmf(10, lambda1New))\n",
    "print(lambda1New/lambda2New)"
   ],
   "id": "1b96f16be49f969d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lambda2New = lambda2/30\n",
    "print(1-stats.poisson.cdf(2, lambda2New))"
   ],
   "id": "19cfb58a8da5a00e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "45bb34ecc0734997"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### linear regression and conf interval on the model",
   "id": "d100f44ca4d9f84e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#task 3\n",
    "n = 40 # normally distributed\n",
    "airMean = 34.66\n",
    "airStd = 10.12\n"
   ],
   "id": "eb3f8fe27562d77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Data\n",
    "batch_sizes = np.array([50, 100, 150, 200, 250, 300, 350, 400, 450, 500])\n",
    "\n",
    "# data to be predicted\n",
    "costs = np.array([2.33, 4.21, 6.01, 7.51, 8.46, 8.93, 9.45, 10.70, 10.55, 10.74])\n",
    "\n",
    "# Fit linear regression model\n",
    "X = sm.add_constant(batch_sizes)  # Add intercept\n",
    "model = sm.OLS(costs, X).fit()\n",
    "\n",
    "# Extract R-squared\n",
    "# r_squared = model.rsquared   -- if required or simply get it through summary\n",
    "\n",
    "print(model.summary(slim=True))\n",
    "\n"
   ],
   "id": "f38db3209389a225",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# this gives a confidence interval for all the variables in the model in the order of the model seen above \n",
    "# so the first confidence interval is for beta_0 or const\n",
    "# and the second is for beta_1 or x1 \n",
    "conf_interval_99 = model.conf_int(alpha=0.01)\n",
    "print(conf_interval_99) "
   ],
   "id": "bd115461e727dde4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ec4366b6ce845e75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#V.1\n",
    "print(24998/46551)"
   ],
   "id": "752598c63c73214d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# V.3 (12)\n",
    "#expected count given that the distribution for both male and female is the same across all age groups \n",
    "# the formula is (row total * column total) / grand total\n",
    "print((28176*24998)/46551)"
   ],
   "id": "d3aae090275b0ca3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# V.4 (13)\n",
    "alpha = 0.05\n",
    "n=28176\n",
    "proportion = 14048/n\n",
    "standardError = np.sqrt((proportion*(1-proportion))/n)\n",
    "zStat = stats.norm.ppf(1-alpha/2)\n",
    "\n",
    "errorMargin = standardError * zStat\n",
    "print(errorMargin) \n",
    "upMarg = proportion + errorMargin\n",
    "lowMarg = proportion - errorMargin\n",
    "print(f\"conf int is low {lowMarg} and up {upMarg}\")\n",
    " "
   ],
   "id": "ed3d3f689ddc89b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### binomial distribution",
   "id": "ef6ef7f93318b657"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#v.5 (14)\n",
    "# remember it is 100 or more so we need to find  area of 99 or less not 100 or less\n",
    "print(1-stats.binom.cdf(99, 190, 0.45))"
   ],
   "id": "327c31776567bb39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### conf interval without quick function",
   "id": "1ecc96490c39279d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#v.III (18)\n",
    "n1, n2 = 25000, 15000 # normally distributed\n",
    "mean1, mean2 = 1250, 1300\n",
    "std1, std2 = 54.24, 28.54 \n",
    "alpha = 0.05\n",
    "\n",
    "meanDiff = mean1-mean2\n",
    "\n",
    "SE = np.sqrt((std1**2 / n1) + (std2**2 / n2))\n",
    "\n",
    "\n",
    "# stError = np.sqrt((proportion*(1-proportion)/n)   # this is for a proportion\n",
    "critValue = stats.norm.ppf((1-alpha/2)) #  \n",
    "# critValue = stats.norm.ppf((1-alpha/2),fDegrees) # for a big sample 29<n\n",
    "marginError = critValue * SE\n",
    "\n",
    "upBound = meanDiff+marginError\n",
    "lowBound = meanDiff-marginError\n",
    "\n",
    "print(f\"Mean Difference: {meanDiff}\")\n",
    "print(f\"Standard Error of the Difference: {SE:.4f}\")\n",
    "print(f\"Critical Z-Value: {critValue:.4f}\")\n",
    "print(f\"Margin of Error: {marginError:.4f}\")\n",
    "print(f\"95% Confidence Interval: ({lowBound:.2f}, {upBound:.2f})\")\n"
   ],
   "id": "db9cbcf18d721d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### two sample t-test and hypothesis test where h0 is not 0 (and if it is)",
   "id": "a40fbd4420f765e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#VIII.2 (19)\n",
    "nullDiff = -50\n",
    "\n",
    "print((meanDiff-nullDiff)/SE)"
   ],
   "id": "d13807c634433694",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#VIII.3 (20)\n",
    "# use when mean of two groups are dependant \n",
    "# if the hypothesis is not simply that the mean difference is 0 \n",
    "# in the example the hypothesis is h_0 : mean_current - mean_new = 0.05\n",
    "currentModel = np.array([7.964, 7.813, 8.299, 8.219, 9.832, 9.829, 9.842, 9.498, 7.023, 8.408])\n",
    "newModel = np.array([7.932, 7.762 , 8.243, 8.174, 9.782, 9.775, 9.794, 9.445, 6.942, 8.347])\n",
    "null_difference = 0.05\n",
    "differences = currentModel - newModel\n",
    "n = len(differences)\n",
    "meanDiff = np.mean(differences)\n",
    "stDeviation = np.std(differences, ddof=1)\n",
    "standardErrorDiff = stDeviation/np.sqrt(n)\n",
    "\n",
    "tStat = (meanDiff - null_difference) / standardErrorDiff\n",
    "\n",
    "# Step 4: Compute the p-value\n",
    "pValueDiff = 2 * (1 - stats.t.cdf(abs(tStat), df=n-1))\n",
    "print(f\"tStat {tStat} pVal {pValueDiff} meandiff {meanDiff} standardErr {standardErrorDiff}\")\n",
    "\n",
    "# OBS!!!! t-statistic and p-value directly if the hypthesis is h_0 : mean_current - mean_new = 0\n",
    "#t_stat, p_value = stats.ttest_rel(currentModel, newModel)\n",
    "#print(t_stat, p_value)"
   ],
   "id": "e78a537072e07277",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### two way anova",
   "id": "95f652087654a484"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#IX.2 (22)\n",
    "\n",
    "pValSupply = stats.f.sf(3.8696, 3,12)\n",
    "pValDay = stats.f.sf(4.6362, 4, 12)\n",
    "print(pValSupply, pValDay)\n",
    "\n",
    "\n",
    "## the two way anova table itself (not nescessary for the task)\n",
    "\n",
    "# Step 1: Create the data\n",
    "data = pd.DataFrame({\n",
    "    \"Strength\": [92.0, 131.0, 74.1, 90.4,  # Day 1\n",
    "                 111.6, 103.5, 52.8, 95.2,  # Day 2\n",
    "                 98.4, 100.0, 82.5, 87.6,  # Day 3\n",
    "                 87.7, 84.7, 94.7, 63.2,  # Day 4\n",
    "                 134.9, 134.5, 107.3, 119.5],  # Day 5\n",
    "    \"Supplier\": [\"A\", \"B\", \"C\", \"D\"] * 5,\n",
    "    \"Day\": [\"Day 1\"] * 4 + [\"Day 2\"] * 4 + [\"Day 3\"] * 4 + [\"Day 4\"] * 4 + [\"Day 5\"] * 4\n",
    "})\n",
    "\n",
    "# Step 2: Fit the two-way ANOVA model\n",
    "model = smf.ols(\"Strength ~ C(Supplier) + C(Day)\", data=data).fit()\n",
    "\n",
    "# Step 3: Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)  # typ=2 for main effects only\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_table)"
   ],
   "id": "7b50e675e687b5b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#X.1 & .2\n",
    "#in both of these the task states that there i no distributional assumption which invalidates the t-test portion of both as a t-test assumes a normal distribution and the solution is therefore to see whether the null hypothesis is true based on the given 2.5% and 97.5% quantiles. if the values (in the first task a return of 20) (second task a difference of 0) are within the bounds of their respective values of said quantiles then the null hypothesis is \"accepted\" (or at least not rejected)"
   ],
   "id": "95cee5a124fdc047",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2023 may\n",
    "### conf int for mean and proportion"
   ],
   "id": "5be16eb9e962c25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nice= stats.norm.ppf(0.85)\n",
    "print(55+nice*19)"
   ],
   "id": "90b569e1764914fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = 8500, 10300, 6800, 10600, 4900, 6200, 10800, 5700, 5100, 9000\n",
    "n= len(data)\n",
    "std = np.std(data)\n",
    "mean = np.mean(data)\n",
    "fDegrees = n-1\n",
    "alpha = 0.01\n",
    "\n",
    "stError = std/np.sqrt(n) # 1.6 this is for a mean\n",
    "# stError = np.sqrt((proportion*(1-proportion)/n)   # this is for a proportion\n",
    "critValue = stats.t.ppf((1-alpha/2),fDegrees) #  for a small smaple 30>n\n",
    "# critValue = stats.norm.ppf((1-alpha/2),fDegrees) # for a big sample 29<n\n",
    "marginError = critValue * stError\n",
    "\n",
    "upBound = mean+marginError\n",
    "lowBound = mean-marginError\n",
    "\n",
    "print(f\"The confidence interval is {lowBound} to {upBound}\")\n",
    "\n"
   ],
   "id": "daca5b16f62c7dd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 99% confidence interval",
   "id": "c94283fca2f92064"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# VI.1\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "data = np.array([8500, 10300, 6800, 10600, 4900, 6200, 10800, 5700, 5100, 9000])\n",
    "sample_mean = 17  # Example: mean duration\n",
    "sample_std = 4.5    # Example: standard deviation\n",
    "sample_size = 40   # Example: sample size\n",
    "confidence_level = 0.99\n",
    "\n",
    "# Calculate Z-score for 99% confidence\n",
    "z_score = stats.norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "\n",
    "# Compute margin of error\n",
    "margin_of_error = z_score * (sample_std / np.sqrt(sample_size))\n",
    "\n",
    "# Calculate confidence interval\n",
    "lower_bound = sample_mean - margin_of_error\n",
    "upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "#THIS SOLVED IT!!!!\n",
    "popmean=10000\n",
    "print(ttest_1samp(data, popmean=popmean).confidence_interval(0.99))\n",
    "\n",
    "t_stat, p_value = ttest_1samp(data,popmean=popmean)\n",
    "\n",
    "print(np.std(data))\n",
    "\n",
    "print(f\"CI: [{lower_bound:.2f};{upper_bound:.2f}]\")"
   ],
   "id": "e65e352d1b793555",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### linear regression",
   "id": "795f5a938d2d139e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#VIII.1 (12)+(13)+(14)\n",
    "#(12)\n",
    "#beta1 slope koefficient (is under year -- estiamte) and times it by 5 years  0.027634*5\n",
    "print(0.027634*5)\n",
    "#asnwer in 3rd option\n",
    "\n",
    "#(13)\n",
    "# tObs = beta 1 (0.027634) / stdErr (0.008736)\n",
    "tObs = 0.027634/0.008736\n",
    "#critical value is found by \n",
    "df = 24 #found in the regression output\n",
    "alpha = 0.01\n",
    "critVal = stats.t.ppf(1-alpha/2, df)\n",
    "print(f\"crit val:{critVal} tObs:{tObs}\")\n",
    "# option 2 is correct since the citIntVal is +-2.8 and tObs is > 2.8\n",
    "\n",
    "#(14)\n",
    "alpha2 = 0.05\n",
    "critVal2 = stats.t.ppf(1-alpha2/2, df)\n",
    "print(f\"crit val:{critVal2}\")"
   ],
   "id": "884dc76ccf329102",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### prediction interval",
   "id": "6c7ec14bf6ad2fd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(15)\n",
    "# Data: Year (independent variable) and DO (dependent variable)\n",
    "year = np.array(range(1990, 2016))\n",
    "DO = np.array([1.52, 2.88, 1.60, 2.24, 2.45, 1.84, 2.03, 2.33, 2.81,\n",
    "               2.46, 2.36, 2.23, 2.81, 2.70, 2.63, 2.00, 2.40, 2.45,\n",
    "               2.48, 2.51, 2.55, 2.77, 2.70, 2.23, 2.88, 3.09])\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'year': year, 'DO': DO})\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = smf.ols('DO ~ year', data=data).fit()\n",
    "\n",
    "# Define the year for prediction (2022 in this case)\n",
    "new_year = pd.DataFrame({'year': [2022]})\n",
    "\n",
    "# Get predictions with confidence and prediction intervals\n",
    "predictions = model.get_prediction(new_year)\n",
    "\n",
    "# Get summary frame (includes prediction interval)\n",
    "pred_summary = predictions.summary_frame(alpha=0.05)  # 95% confidence level\n",
    "\n",
    "print(pred_summary)\n",
    "\n",
    "#below mean ci is the confidence interval and obs ci is the prediction interval \n",
    "# answer is 1 as the value is within the prediction interval"
   ],
   "id": "e643df84a49a5cb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### exponential distribution find the chance of event in x time",
   "id": "921b4bc5e17e0035"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#IX.1(16)\n",
    "# Parameters\n",
    "lambda_val = 1/2 # rate at which events occur pr unit of time fx 1 for an event every 1 hour 1/2 for an event every two hours...\n",
    "rate_param = 1 / lambda_val # inverse of lambda val and defines how much time for 1 event ao here 15 units of time before an event\n",
    "k = 1 # find cumulative probability of \n",
    "\n",
    "# Calculate Exponential CDF for P(X < k)\n",
    "expo_cdf1 = stats.expon.cdf(1, scale=rate_param)\n",
    "expo_cdf2 = 1-stats.expon.cdf(2, scale=rate_param)\n",
    "expo_cdf = 1-(expo_cdf1+expo_cdf2)\n",
    "print(f\"P(X < {k}) = {expo_cdf}\")\n",
    "\n",
    "# Calculate mean and variance\n",
    "mean, var = stats.expon.stats(scale=rate_param)\n",
    "#print(f\"Mean: {mean}\")\n",
    "#print(f\"Variance: {var}\")\n",
    "#answer is number 5"
   ],
   "id": "cb7777299f7bc11f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### simulation",
   "id": "5e76add88f016afb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#X.1 (17)\n",
    "import numpy as np\n",
    "\n",
    "# Given heights data\n",
    "heights = np.array([162, 172, 178, 154, 173, 174, 166, 166, 164, 167, 163, 165, 170, 177])\n",
    "\n",
    "# Parameters\n",
    "n_simulations = 1000\n",
    "np.random.seed(1234)  # Ensure reproducibility\n",
    "\n",
    "# Step 1: Estimate mean and standard deviation from the data\n",
    "mean_height = np.mean(heights)\n",
    "std_height = np.std(heights, ddof=1)\n",
    "\n",
    "# Step 2: Generate bootstrap samples from normal distribution\n",
    "bootstrap_samples = np.random.normal(loc=mean_height, scale=std_height, size=(n_simulations, len(heights)))\n",
    "\n",
    "# Step 3: Compute the median for each bootstrap sample\n",
    "bootstrap_medians = np.median(bootstrap_samples, axis=1)\n",
    "\n",
    "# Step 4: Calculate the 95% confidence interval for the median\n",
    "ci_lower, ci_upper = np.percentile(bootstrap_medians, [2.5, 97.5])\n",
    "\n",
    "# Display the result\n",
    "print(f\"95% Confidence Interval for the Median: [{ci_lower:.2f}, {ci_upper:.2f}]\")"
   ],
   "id": "ac5dd3b473a211c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### two way anova and bonferroni",
   "id": "35ccf12cbcf18050"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#XI.1 (20)\n",
    "# freedom degree is number of categories -1 so 4 paint categories = 3 fd\n",
    "# two methods = 1 fd\n",
    "# residuals fd = paintfd (3) * methodfd (1) = 3 fd\n",
    "# aswer is 4 because two method observations pr paint type so 2*4 = 8\n",
    "\n",
    "#XI.2 (21)\n",
    "# Total significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Number of categories (k) for pairwise comparisons\n",
    "k = 4\n",
    "\n",
    "# Calculate the number of pairwise comparisons (m)\n",
    "m = k * (k - 1) // 2  # Combination formula for k choose 2\n",
    "\n",
    "# Calculate Bonferroni-corrected alpha\n",
    "alpha_bonferroni = alpha / m\n",
    "\n",
    "print(f\"Number of comparisons (m): {m}\")\n",
    "print(f\"Bonferroni-corrected alpha: {alpha_bonferroni:.5f}\")\n",
    "#the asnwer lies in the calculation of alpha_bonferroni so if we insert numbers in the formula we get\n",
    "# so the answer is alpha/m = 0.05/6 so option 4"
   ],
   "id": "6a1f5955c5005c56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### varianse and hypotesis test and choice of test method",
   "id": "e3015217446b474d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#XII.1 (23)\n",
    "# Data from the problem\n",
    "consumption = np.array([5.4, 4.5, 4.6, 4.4, 4.9, 3.3, 4.1, 4.6, 4.8, 4.6,\n",
    "                        5.2, 4.7, 4.4, 4.8, 4.8, 5.2, 4.9, 4.8, 5.6, 5.5])\n",
    "\n",
    "# Calculate the total variation (SST)\n",
    "overall_mean = np.mean(consumption)\n",
    "sst = np.sum((consumption - overall_mean) ** 2)\n",
    "\n",
    "print(f\"Total Variation (SST): {sst}\")\n",
    "\n",
    "#XII.2 (24)\n",
    "\n",
    "# we use a one-way anova because we are comparing means across multiple groups (months)\n",
    "# to see how to choose between one way or two way see anove in random notes\n",
    "\n",
    "# Data\n",
    "consumption = np.array([5.4, 4.5, 4.6, 4.4, 4.9, 3.3, 4.1, 4.6, 4.8, 4.6,\n",
    "                        5.2, 4.7, 4.4, 4.8, 4.8, 5.2, 4.9, 4.8, 5.6, 5.5])\n",
    "month = ['Feb'] * 5 + ['May'] * 5 + ['Aug'] * 5 + ['Nov'] * 5\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Consumption': consumption, 'Month': month})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "anova_model = smf.ols('Consumption ~ C(Month)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(anova_model, typ=2)\n",
    "\n",
    "# Output the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# as we see in the one-way anova the p-value is less than the significance level so we therefore reject the null hypothesis og 0.05 \n",
    "# 0.05 > 0.0303\n",
    "# the answer is option 5 as that is the one which states that we use one-way anova and reject the hypothesis as the p-value is 0.03 < 0.05"
   ],
   "id": "29553b905348457e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### poisson problem and variance of poisson ",
   "id": "14aacfa4fdf75f3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#XIII.1 (24)\n",
    "# in a poisson distribution the variance is always equal to the mean so \n",
    "# variance = mean = 48\n",
    "# answer 2 is correct\n",
    "\n",
    "#XIII.2 (25)\n",
    "# Parameters\n",
    "# when we have 48 calls an hour to find how many calls we expect in 5 min we say \n",
    "min5 = 60/5 # = 12\n",
    "print(min5)\n",
    "lambda_val = 48/min5  # mean (expected number of events) = 4\n",
    "print(lambda_val)\n",
    "k = 1           # lower limit of events for the \"greater than\" probability because we want to find the probability of 1 or lower\n",
    "\n",
    "# Calculate Poisson CDF for P(X > k)\n",
    "poisson_prob_greater = 1 - stats.poisson.cdf(k, lambda_val)\n",
    "\n",
    "print(f\"P(X > {k}) = {poisson_prob_greater}\")"
   ],
   "id": "eabd64b5ee7b6ff5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### confidence interval with z-score",
   "id": "8f0082d5f328721a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#XIV.1 (26)\n",
    "# Given data\n",
    "p_hat = 24 / 100  # Proportion of \"Meget svært\"\n",
    "n = 100  # Total number of responses\n",
    "z = 1.96  # Z-value for 95% confidence level\n",
    "\n",
    "# Standard error calculation\n",
    "se = np.sqrt((p_hat * (1 - p_hat)) / n)\n",
    "print(se)\n",
    "# Confidence interval calculation\n",
    "lower_bound = p_hat - z * se\n",
    "upper_bound = p_hat + z * se\n",
    "\n",
    "print(f\"95% Confidence Interval: ({lower_bound:.4f}, {upper_bound:.4f})\")\n",
    "\n",
    "print(0.24 + 1.96*np.sqrt(0.1824/100))\n",
    "print(0.24 - 1.96*np.sqrt(0.1824/100))\n",
    "\n",
    "# asnwer number 2 (this one is retarded because you have to manually calculate the asnwers)\n",
    "\n",
    "#XIV.2 (27)\n",
    "# literally the same retard problem\n",
    "\n",
    "# Given data\n",
    "p_hat = 5 / 101  # Proportion of \"Meget svært\"\n",
    "n = 101  # Total number of responses\n",
    "z = 1.96  # Z-value for 95% confidence level\n",
    "\n",
    "# Standard error calculation\n",
    "se = np.sqrt((p_hat * (1 - p_hat)) / n)\n",
    "\n",
    "# Confidence interval calculation\n",
    "lower_bound = p_hat - z * se\n",
    "upper_bound = p_hat + z * se\n",
    "\n",
    "print(f\"95% Confidence Interval: ({lower_bound:.6f}, {upper_bound:.6f})\")\n",
    "\n",
    "print(0.0666667 + 1.96*np.sqrt(0.0622/105))\n",
    "print(0.0666667 - 1.96*np.sqrt(0.0622/105))"
   ],
   "id": "3a6979543cfe42a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### chi-square test of independence",
   "id": "7e7a785f24ab945e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "    #XIV.3 (28)\n",
    "# Data from the table for 2021\n",
    "ledig = np.array([11, 15, 27, 24, 24])  # Responses for \"ledig\"\n",
    "beskaeftiget = np.array([20, 30, 29, 12, 5])  # Responses for \"beskæftiget\"\n",
    "\n",
    "# Perform a Chi-square test\n",
    "chi2, p_value, _, _ = stats.chi2_contingency([ledig, beskaeftiget])\n",
    "\n",
    "# Print results\n",
    "print(f\"Chi-squared value: {chi2}\") # small value indicates close to expected data and vice versa \n",
    "print(f\"p-value: {p_value:.12f}\") # :.xf signifies number of digits\n",
    "\n",
    "# Decision at 5% significance level\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference (reject H0).\")\n",
    "else:\n",
    "    print(\"There is no significant difference (fail to reject H0).\")\n",
    "    \n",
    "    "
   ],
   "id": "4e20cc0f6c9041c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# XIV.4 (29)\n",
    "# Given data\n",
    "total_nemt = 82  # Total responses for \"Nemt\"\n",
    "total_2019 = 101  # Total responses for 2019\n",
    "total_responses = 503  # Total responses for all years\n",
    "\n",
    "# Calculate expected value\n",
    "expected_value = (total_nemt * total_2019) / total_responses\n",
    "print(expected_value)"
   ],
   "id": "94aaddcf35272d5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### p-value for the Chi-Square test using the given chi-squared statistic and degrees of freedom",
   "id": "2ac4a6859c27cd4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#XIV.5 (30)\n",
    "# Given data\n",
    "chi2_stat = 4.5303\n",
    "df = 16\n",
    "\n",
    "# Calculate p-value for the Chi-Square test\n",
    "p_value = 1 - stats.chi2.cdf(chi2_stat, df)\n",
    "\n",
    "print(f\"The p-value is: {p_value}\")\n",
    "# correct asnwer is number 3"
   ],
   "id": "4c1b00c018d44c11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2023 june ",
   "id": "8fb0203c99d162a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### One-Way ANOVA",
   "id": "ea489176533096de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (1)\n",
    "# Data for the three groups\n",
    "group1 = [27, 22, 18, 26, 24]\n",
    "group2 = [32, 22, 32, 25, 25]\n",
    "group3 = [29, 25, 30, 30, 24]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
    "print(f\"Problem 1 - ANOVA F-Statistic: {f_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "# answer is number 2"
   ],
   "id": "fb1ac1c7922ffb9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculating Residual Degrees of Freedom and Mean Square Error (ANOVA)",
   "id": "cf70acfec3c398d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(2)\n",
    "# Problem Setup\n",
    "n = 15  # Total number of observations\n",
    "k = 3   # Number of groups\n",
    "ss_residuals = 440.80  # Sum of squares of residuals\n",
    "\n",
    "# Degrees of Freedom for Residuals\n",
    "df_residuals = n - k  # Correct calculation\n",
    "print(f\"Degrees of Freedom (Residuals): {df_residuals}\")\n",
    "\n",
    "# Mean Square Residuals\n",
    "ms_residuals = ss_residuals / df_residuals  # Correct calculation\n",
    "print(f\"Mean Square Residuals: {ms_residuals:.3f}\")\n",
    "\n",
    "# Validate Correct Option\n",
    "if df_residuals == 12 and np.isclose(ms_residuals, 36.733, atol=0.001):\n",
    "    print(\"Correct option: 3\")\n",
    "else:\n",
    "    print(\"Recheck calculations or data.\")"
   ],
   "id": "14b8342648f1d287",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mean and Variance of a Linear Combination of Random Variables",
   "id": "ecb8cf5000538ebb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(3)\n",
    "# Let b1, b2 be coefficients and µ be the mean\n",
    "b1, b2, a1 = 2, 3, 5  # Example coefficients\n",
    "mu = 10  # Mean of X\n",
    "var_x = 4  # Variance of X (since X ~ N(µ, 2^2))\n",
    "\n",
    "# Calculate mean and variance of Y1\n",
    "mean_y1 = a1 + (b1 + b2) * mu\n",
    "variance_y1 = (b1 + b2)**2 * var_x\n",
    "\n",
    "print(f\"Problem 3 - E(Y1): {mean_y1}, V(Y1): {variance_y1}\")\n",
    "# as seen in the method of calculation the answer is 1"
   ],
   "id": "950c00a1f45f0c8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sigmoid Function Variance (Logistic Function)",
   "id": "7403aa498ddb4844"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(4)\n",
    "# Logistic function for Y2\n",
    "a2, b2 = 10, -1  # Given coefficients\n",
    "x = np.array([0, 10, 20])  # Example means\n",
    "\n",
    "# Calculate logistic function for each value of x\n",
    "y2 = 1 / (1 + np.exp(a2 + b2 * x))\n",
    "var_y2 = y2 * (1 - y2)  # Variance of Bernoulli variable\n",
    "\n",
    "print(f\"Problem 4 - Variance at µ=0: {var_y2[0]:.4f}, µ=10: {var_y2[1]:.4f}, µ=20: {var_y2[2]:.4f}\")\n",
    "# answer is 4 "
   ],
   "id": "858707e09e223e7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Paired T-Test (Testing Mean Difference Between Two Exam Scores)",
   "id": "3a4fafd349617890"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(5)\n",
    "# Example data for student exam scores\n",
    "# use what test to use function\n",
    "exam_part1 = [78, 82, 74, 90, 68]\n",
    "exam_part2 = [80, 85, 72, 88, 70]\n",
    "\n",
    "# Perform paired t-test\n",
    "t_stat, p_value = stats.ttest_rel(exam_part1, exam_part2)\n",
    "print(f\"Problem 5 - Paired T-Test Statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "# answer is 5 "
   ],
   "id": "f56dc81d87937180",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Confidence Interval for the Difference in Means (Unequal Variances) (fdegrees with welch)",
   "id": "e949445276db3d84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(6)\n",
    "# Given data for the two universities\n",
    "mean_A, mean_B = 736.4, 769.9\n",
    "var_A, var_B = 169.1, 402.7\n",
    "n_A, n_B = 589, 240\n",
    "\n",
    "# Calculate standard error\n",
    "se = np.sqrt(var_A / n_A + var_B / n_B)\n",
    "\n",
    "# Calculate degrees of freedom (Welch-Satterthwaite)\n",
    "df = ((var_A / n_A + var_B / n_B)**2) / ((var_A / n_A)**2 / (n_A - 1) + (var_B / n_B)**2 / (n_B - 1))\n",
    "\n",
    "# Calculate t-critical for 90% CI\n",
    "t_critical = stats.t.ppf(0.95, df)\n",
    "\n",
    "print(f\"Problem 6 - Degrees of Freedom: {df:.4f}, T-Critical: {t_critical:.4f}\")\n",
    "# we use the 95% quantile because we account for 5% on either tail when finding 90% confidence interval\n",
    "# so with freedom degrees 323.93 and 95% quantile answer is 5 "
   ],
   "id": "bcd90ab230ea55a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Confidence Interval for Proportion",
   "id": "62ed0c3dc0467325"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(7)\n",
    "# Given survival data\n",
    "survived = 709\n",
    "total = 2201\n",
    "p_hat = survived / total\n",
    "\n",
    "# Calculate standard error for proportion\n",
    "se = np.sqrt(p_hat * (1 - p_hat) / total)\n",
    "\n",
    "# Calculate z-critical value for 95% CI\n",
    "z_critical = stats.norm.ppf(0.975)\n",
    "\n",
    "# Calculate margin of error and confidence interval\n",
    "margin_of_error = z_critical * se\n",
    "ci_lower = p_hat - margin_of_error\n",
    "ci_upper = p_hat + margin_of_error\n",
    "\n",
    "print(f\"Problem 7 - 95% CI for proportion: ({ci_lower:.4f}, {ci_upper:.4f})\")\n",
    "# answer is 2"
   ],
   "id": "432c1a80b395bf14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test of Independence (Chi-Square Test on Titanic Data)",
   "id": "f3b578220e527d1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (8)\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Data\n",
    "s = np.array([178, 212])  # Success counts for crew and 3rd class passengers\n",
    "n = np.array([706, 885])  # Total counts for crew and 3rd class passengers\n",
    "\n",
    "# Perform the two-sample z-test for proportions\n",
    "z_stat, p_value = proportions_ztest(s, n)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ],
   "id": "55a7cf3ec00f2715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Chi-Square Test for Independence",
   "id": "18672118e05f38c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(9)\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Observed survival counts across classes\n",
    "observed = np.array([\n",
    "    [202, 117, 178, 212],  # Survived\n",
    "    [123, 168, 528, 673]   # Not Survived\n",
    "])\n",
    "\n",
    "# Step 1: Compute the total and expected counts\n",
    "row_totals = observed.sum(axis=1)\n",
    "col_totals = observed.sum(axis=0)\n",
    "grand_total = observed.sum()\n",
    "\n",
    "# Calculate expected frequencies\n",
    "expected = np.outer(row_totals, col_totals) / grand_total\n",
    "\n",
    "# Step 2: Compute the chi-square statistic\n",
    "q_stat = ((observed - expected) ** 2 / expected).sum()\n",
    "\n",
    "# Step 3: Determine the degrees of freedom\n",
    "df = (observed.shape[0] - 1) * (observed.shape[1] - 1)\n",
    "\n",
    "# Step 4: Find the critical value at α = 0.05\n",
    "alpha = 0.05\n",
    "critical_value = chi2.ppf(1 - alpha, df)\n",
    "\n",
    "# Step 5: Determine significance\n",
    "significant = q_stat > critical_value\n",
    "\n",
    "# Output the results\n",
    "print(f\"Test Statistic (q): {q_stat:.2f}\")\n",
    "print(f\"Critical Value (CV): {critical_value:.2f}\")\n",
    "print(f\"Is there a significant difference? {'Yes' if significant else 'No'}\")"
   ],
   "id": "282d4913fd1b51b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Confidence Interval for a Proportion",
   "id": "a26b88eea62514db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(10)\n",
    "# Given data\n",
    "p_1st = 0.62  # Survival probability of 1st class passengers\n",
    "p_rest = 0.27  # Average survival probability of other passengers\n",
    "n_1st = 325  # Number of 1st class passengers\n",
    "n_rest = 571  # Number of other passengers\n",
    "\n",
    "# Difference in proportions\n",
    "p_diff = p_1st - p_rest\n",
    "\n",
    "# Standard error calculation\n",
    "se_diff = np.sqrt((p_1st * (1 - p_1st) / n_1st) + (p_rest * (1 - p_rest) / n_rest))\n",
    "\n",
    "# Confidence interval (95%)\n",
    "z_critical = stats.norm.ppf(1 - 0.05 / 2)  # Two-tailed test\n",
    "ci_lower = p_diff - z_critical * se_diff\n",
    "ci_upper = p_diff + z_critical * se_diff\n",
    "\n",
    "# Display the confidence interval\n",
    "print(f\"Confidence Interval: [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "\n",
    "# Conclusion\n",
    "if 0.2 > ci_lower and 0.2 < ci_upper:\n",
    "    print(\"0.2 is included in the confidence interval. There is no significant difference.\")\n",
    "else:\n",
    "    print(\"0.2 is not included in the confidence interval. There is a significant difference.\")"
   ],
   "id": "db36f29c90b0217b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### std of sum of independant random variables",
   "id": "cb578f398143af0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(11)\n",
    "# Statistical Concept: Standard deviation of the sum of independent random variables\n",
    "# Purpose: Calculate the standard deviation of the total trash collected by the class.\n",
    "# Given data\n",
    "n_children = 20  # Number of children\n",
    "std_per_child = 0.2  # Standard deviation of trash collected per child (in kg)\n",
    "\n",
    "# Standard deviation of the total collected trash\n",
    "std_total = std_per_child * np.sqrt(n_children)\n",
    "\n",
    "# Display the result\n",
    "print(f\"The standard deviation of the total trash collected: {std_total:.2f} kg\")"
   ],
   "id": "5b9337ce807601ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The hypergeometric distribution",
   "id": "c42b98b23cf7624c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(12)\n",
    "# Statistical Concept: Hypergeometric distribution\n",
    "# Purpose: Calculate the probability of selecting exactly 3 plastic items out of 5 random selections.\n",
    "\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "# Given data\n",
    "total_items = 21  # Total number of items\n",
    "plastic_items = 6  # Number of plastic items\n",
    "sample_size = 5  # Number of items picked\n",
    "successes = 3  # Desired number of plastic items\n",
    "\n",
    "# Calculate the probability\n",
    "probability = hypergeom.pmf(successes, total_items, plastic_items, sample_size)\n",
    "\n",
    "# Display the result\n",
    "print(f\"The probability of selecting exactly 3 plastic items: {probability:.3f}\")"
   ],
   "id": "2ef2258fc39f18ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The binomial distribution",
   "id": "9bc2b604dc13dbb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(13)\n",
    "# Statistical Concept: Binomial distribution\n",
    "# Purpose: Calculate the probability of selecting exactly 3 plastic items out of 18 based on a 32% plastic probability.\n",
    "\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Given data\n",
    "n = 18  # Total number of items collected\n",
    "p = 0.32  # Probability of an item being plastic\n",
    "k = 3  # Desired number of plastic items\n",
    "\n",
    "# Calculate the probability\n",
    "probability = binom.pmf(k, n, p)\n",
    "\n",
    "# Display the result\n",
    "print(f\"The probability of selecting exactly 3 plastic items: {probability:.3f}\")"
   ],
   "id": "ef6b490aa0580023",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### chi-squared distribution is used to calculate confidence intervals for the variance or standard deviation",
   "id": "c4e040efe2c7409c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(14)\n",
    "# Statistical Concept: Chi-squared distribution\n",
    "# Purpose: Calculate the 95% confidence interval for the standard deviation.\n",
    "\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Given data\n",
    "n = 26  # Sample size\n",
    "s = 0.75  # Observed standard deviation\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Calculate the chi-squared critical values\n",
    "chi2_lower = chi2.ppf(alpha / 2, df)\n",
    "chi2_upper = chi2.ppf(1 - alpha / 2, df)\n",
    "\n",
    "# Calculate the confidence interval for the variance\n",
    "lower_variance = (df * s**2) / chi2_upper\n",
    "upper_variance = (df * s**2) / chi2_lower\n",
    "\n",
    "# Convert to standard deviation\n",
    "lower_sd = np.sqrt(lower_variance)\n",
    "upper_sd = np.sqrt(upper_variance)\n",
    "\n",
    "# Display the confidence interval\n",
    "print(f\"The 95% confidence interval for the standard deviation is: [{lower_sd:.3f}, {upper_sd:.3f}]\")"
   ],
   "id": "2f88f91cef8843a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### t-test for a single sample mean",
   "id": "bbda85d36da2f5dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(15)\n",
    "# Problem parameters\n",
    "sample_mean = 200.3  # Observed sample mean\n",
    "pop_mean = 200       # Hypothesized population mean\n",
    "std_dev = 0.75       # Observed sample standard deviation\n",
    "n = 26               # Sample size\n",
    "df = n - 1           # Degrees of freedom\n",
    "\n",
    "# Calculate the t-statistic\n",
    "t_stat = (sample_mean - pop_mean) / (std_dev / (n ** 0.5))\n",
    "\n",
    "# Critical t-values for significance levels\n",
    "critical_t_5 = stats.t.ppf(1 - 0.05 / 2, df)  # Two-tailed 5%\n",
    "critical_t_10 = stats.t.ppf(1 - 0.10 / 2, df)  # Two-tailed 10%\n",
    "\n",
    "# Print t-statistic and critical values\n",
    "print(f\"T-statistic: {t_stat:.3f}\")\n",
    "print(f\"Critical t-value at 5% (two-tailed): ±{critical_t_5:.3f}\")\n",
    "print(f\"Critical t-value at 10% (two-tailed): ±{critical_t_10:.3f}\")\n",
    "\n",
    "# Conclusion based on t-statistic\n",
    "if abs(t_stat) > critical_t_10:\n",
    "    conclusion = \"Rejected at 10%\"\n",
    "else:\n",
    "    conclusion = \"Accepted at 10%\"\n",
    "\n",
    "if abs(t_stat) > critical_t_5:\n",
    "    conclusion_5 = \"Rejected at 5%\"\n",
    "else:\n",
    "    conclusion_5 = \"Accepted at 5%\"\n",
    "\n",
    "print(f\"Conclusion at 5%: {conclusion_5}\")\n",
    "print(f\"Conclusion at 10%: {conclusion}\")\n",
    "\n",
    "# Correct answer based on the solution\n",
    "correct_answer = \"Option 5: Rejected at 10%\"\n",
    "print(f\"Correct Answer: {correct_answer}\")"
   ],
   "id": "3c5007dbb9470f74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sample Size Calculation for Hypothesis Testing",
   "id": "93de3aa28e2a4359"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(16)\n",
    "# Parameters for the problem\n",
    "mu_difference = 0.3  # Difference to detect\n",
    "sigma = 0.75  # Standard deviation\n",
    "alpha = 0.05  # Type I error (significance level)\n",
    "beta = 0.05  # Type II error (1 - power)\n",
    "z_alpha = stats.norm.ppf(1 - alpha / 2)  # Critical z-value for two-sided test\n",
    "z_beta = stats.norm.ppf(1 - beta)  # Critical z-value for power\n",
    "\n",
    "# Calculate the minimum sample size\n",
    "n_normal = ((z_alpha + z_beta) * sigma / mu_difference) ** 2\n",
    "n_normal_rounded = np.ceil(n_normal)  # Rounded up sample size to nearest integer\n",
    "\n",
    "# Result\n",
    "print(f\"Minimum sample size needed: {n_normal_rounded}\")\n",
    "# the normal approximation is +2"
   ],
   "id": "fe3a52d6d483cac3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Regression Degrees of Freedom",
   "id": "4d194efc771c2b6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(17)\n",
    "# Statistical Concept: Linear Regression Degrees of Freedom\n",
    "\n",
    "# Degrees of freedom for residuals (given in the problem)\n",
    "df_residual = 165\n",
    "\n",
    "# Number of predictors (x1 and x2) + intercept\n",
    "n_predictors = 2  # x1 and x2 (intercept is implicitly included)\n",
    "\n",
    "# Total number of observations\n",
    "n_observations = df_residual + n_predictors + 1\n",
    "\n",
    "# Output the result\n",
    "print(f\"Total number of observations: {n_observations}\")"
   ],
   "id": "cc82e3e4567eeed8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multiple Linear Regression",
   "id": "df10173ce092308a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "#(18)\n",
    "# Given t-statistics and standard errors\n",
    "coef_table = {\n",
    "    \"Coefficients\": [\"Intercept\", \"x1\", \"x2\"],\n",
    "    \"Estimate\": [6.43959, 0.40303, 0.20019],\n",
    "    \"Std_Error\": [0.01468, 0.02076, 0.02076],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(coef_table)\n",
    "\n",
    "# Calculate t-values\n",
    "df[\"t_value\"] = df[\"Estimate\"] / df[\"Std_Error\"]\n",
    "\n",
    "# Calculate p-values (two-tailed test)\n",
    "from scipy.stats import t\n",
    "degrees_of_freedom = 165  # Residual degrees of freedom\n",
    "df[\"p_value\"] = 2 * (1 - t.cdf(abs(df[\"t_value\"]), df=degrees_of_freedom))\n",
    "\n",
    "# Extract p-values\n",
    "pv1, pv2, pv3 = df[\"p_value\"]\n",
    "\n",
    "# Determine the order\n",
    "order = sorted([(\"pv1\", pv1), (\"pv2\", pv2), (\"pv3\", pv3)], key=lambda x: x[1])\n",
    "\n",
    "# Print results\n",
    "print(\"Order of p-values (from smallest to largest):\")\n",
    "for label, value in order:\n",
    "    print(f\"{label}: {value:.6f}\")\n",
    "\n",
    "# Answer: Based on the order\n",
    "if order == [(\"pv2\", pv2), (\"pv3\", pv3), (\"pv1\", pv1)]:\n",
    "    print(\"Answer: Option 1 (pv2 < pv3 < pv1)\")\n",
    "elif order == [(\"pv1\", pv1), (\"pv2\", pv2), (\"pv3\", pv3)]:\n",
    "    print(\"Answer: Option 2 (pv1 < pv2 < pv3)\")\n",
    "elif order == [(\"pv1\", pv1), (\"pv3\", pv3), (\"pv2\", pv2)]:\n",
    "    print(\"Answer: Option 3 (pv1 < pv3 < pv2)\")\n",
    "elif order == [(\"pv3\", pv3), (\"pv1\", pv1), (\"pv2\", pv2)]:\n",
    "    print(\"Answer: Option 4 (pv3 < pv1 < pv2)\")\n",
    "elif order == [(\"pv1\", pv1), (\"pv2\", pv2), (\"pv3\", pv3)] and pv2 == pv3:\n",
    "    print(\"Answer: Option 5 (pv1 < pv2 = pv3)\")"
   ],
   "id": "d104667ccba5523d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Residual Diagnostics",
   "id": "8f884718c4449b5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(19)\n",
    "# Observations and corresponding statements\n",
    "statements = {\n",
    "    1: \"Based on figure A we should consider log-transforming the outcome\",\n",
    "    2: \"The residuals seem to be independent (figure C)\",\n",
    "    3: \"The normality assumption is clearly violated (figure A)\",\n",
    "    4: \"The residuals seem to be normally distributed (figure B)\",\n",
    "    5: \"There are still systematic effects related to time of day (figure D)\",\n",
    "}\n",
    "\n",
    "# Correct answers based on observations\n",
    "correct_answer = [5]\n",
    "\n",
    "# Display the correct answer\n",
    "print(\"Correct Answer(s):\")\n",
    "for i in correct_answer:\n",
    "    print(f\"{i}: {statements[i]}\")"
   ],
   "id": "d3c0e66ad1ca079a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### standard error estimation for the mean when no predictors are included in the model.",
   "id": "b66a0d1849154f30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(20)\n",
    "# Given values\n",
    "variance = 0.137  # Variance of the outcome variable\n",
    "n = 166  # Number of observations\n",
    "\n",
    "# Calculate the standard error\n",
    "standard_error = np.sqrt(variance / n)\n",
    "\n",
    "# Print the result\n",
    "print(f\"The standard error related to the estimate of β0 is: {standard_error:.5f}\")\n",
    "\n",
    "# Determine the closest answer from the options\n",
    "answers = [0.0147, 0.00990, 0.00734, 0.0208, 0.0106]\n",
    "closest_answer = min(answers, key=lambda x: abs(x - standard_error))\n",
    "print(f\"The closest answer is: {closest_answer}\")"
   ],
   "id": "25937bab2407e0f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### linear regression to determine the 99% confidence interval",
   "id": "cbd74a2c2c8af473"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(21)\n",
    "# Given data\n",
    "wind = np.array([1063, 1450, 879, 1980, 406, 1542, 1212, 1157, 1730, 1105, 775, 856, 802, 851])\n",
    "elpris = np.array([26.84, 24.87, 21.65, 13.26, 24.49, 21.90, 23.29, 22.47, 19.26, 27.86, 27.96, 20.85, 21.83, 34.04])\n",
    "\n",
    "# Linear regression\n",
    "X = sm.add_constant(wind)  # Add intercept\n",
    "model = sm.OLS(elpris, X).fit()\n",
    "\n",
    "# Extract slope (beta1) and standard error\n",
    "beta1 = model.params[1]\n",
    "se_beta1 = model.bse[1]\n",
    "\n",
    "# Degrees of freedom\n",
    "df = len(wind) - 2\n",
    "\n",
    "# 99% confidence interval\n",
    "t_critical = stats.t.ppf(0.995, df)  # Two-tailed t-value for 99% confidence\n",
    "ci_lower = beta1 - t_critical * se_beta1\n",
    "ci_upper = beta1 + t_critical * se_beta1\n",
    "\n",
    "# Output\n",
    "print(f\"99% Confidence Interval for β1: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "\n",
    "# Closest match\n",
    "answers = [\n",
    "    [-0.0148, 0.0017],\n",
    "    [-0.0124, -0.0007],\n",
    "    [-0.0066, 0.0027],\n",
    "    [21.16, 40.87],\n",
    "]\n",
    "closest_answer = min(answers, key=lambda x: abs(ci_lower - x[0]) + abs(ci_upper - x[1]))\n",
    "print(f\"The closest answer is: {closest_answer}\")"
   ],
   "id": "e030b03be340b4e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### linear regression to compute the prediction interval for a given input",
   "id": "f45bf0ce28f6754a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(22)\n",
    "# Given data\n",
    "wind = np.array([1063, 1450, 879, 1980, 406, 1542, 1212, 1157, 1730, 1105, 775, 856, 802, 851])\n",
    "elpris = np.array([26.84, 24.87, 21.65, 13.26, 24.49, 21.90, 23.29, 22.47, 19.26, 27.86, 27.96, 20.85, 21.83, 34.04])\n",
    "\n",
    "# Linear regression\n",
    "X = sm.add_constant(wind)  # Add intercept\n",
    "model = sm.OLS(elpris, X).fit()\n",
    "\n",
    "# Prediction at wind = 1000\n",
    "new_wind = np.array([1, 1000])  # Include constant term\n",
    "prediction = model.get_prediction(new_wind)\n",
    "\n",
    "# Extract 95% prediction interval\n",
    "pi_lower, pi_upper = prediction.summary_frame(alpha=0.05).iloc[0][['obs_ci_lower', 'obs_ci_upper']]\n",
    "\n",
    "# Output\n",
    "print(f\"95% Prediction Interval: [{pi_lower:.2f}, {pi_upper:.2f}]\")\n",
    "\n",
    "# Closest match\n",
    "answers = [\n",
    "    [0.70, 12.41],\n",
    "    [11.41, 37.50],\n",
    "    [15.15, 33.76],\n",
    "    [21.95, 26.97],\n",
    "    [23.98, 38.05],\n",
    "]\n",
    "closest_answer = min(answers, key=lambda x: abs(pi_lower - x[0]) + abs(pi_upper - x[1]))\n",
    "print(f\"The closest answer is: {closest_answer}\")"
   ],
   "id": "bee9f352a0e7f91f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### two-way ANOVA understanding the model\n",
    "(23)\n",
    "The model equation is:\n",
    "$$\n",
    "Y_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}\n",
    "$$\n",
    "Where:\n",
    "\t•\t \\mu : Overall mean of the response variable (plant growth).\n",
    "\t•\t \\alpha_i : Effect of the i-th level of the first factor (fertilizer type).\n",
    "\t•\t \\beta_j : Effect of the j-th level of the second factor (watering frequency).\n",
    "\t•\t \\epsilon_{ij} : Error term assumed to follow N(0, \\sigma^2).\n",
    "\n",
    "The question asks about the interpretation of  \\alpha_i .\n",
    "\n",
    "Correct Answer:\n",
    "\n",
    "Option 3:\n",
    " \\alpha_i  denotes the effect size for fertilizer.  \\alpha_i \\neq 0  implies that the expected plant growth depends on fertilizer type.\n",
    "\n",
    "Reasoning:\n",
    "\t•\t \\alpha_i  represents the deviation of the i-th fertilizer’s effect from the overall mean.\n",
    "\t•\tIt is unrelated to watering frequency ( \\beta_j ).\n",
    "\t•\t \\alpha_i = 0  indicates no effect of fertilizer type on plant growth."
   ],
   "id": "6d258f32c283b018"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### two-way ANOVA and the F-test for testing the equality of means among different groups",
   "id": "2a131f4cb976e7f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(24)\n",
    "# Given F-value from the ANOVA table\n",
    "F_obs = 78.766  # Observed F-statistic for Fertilizer\n",
    "df1 = 1         # Degrees of freedom for Fertilizer\n",
    "df2 = 2         # Degrees of freedom for Residuals\n",
    "alpha = 0.05    # Significance level\n",
    "\n",
    "# Calculate critical F-value\n",
    "F_crit = stats.f.ppf(1 - alpha, df1, df2)\n",
    "\n",
    "# Determine the result of the hypothesis test\n",
    "if F_obs > F_crit:\n",
    "    result = \"Reject the null hypothesis. Significant difference exists among fertilizers.\"\n",
    "else:\n",
    "    result = \"Fail to reject the null hypothesis. No significant difference exists among fertilizers.\"\n",
    "\n",
    "# Output\n",
    "print(f\"Critical F-value (F_crit): {F_crit:.2f}\")\n",
    "print(f\"Observed F-value (F_obs): {F_obs:.2f}\")\n",
    "print(f\"Conclusion: {result}\")"
   ],
   "id": "7ac4f0893ccc6ed0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### boxplot to understand distributions and proportions of data",
   "id": "4bcf3d0123c3a7fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(26)\n",
    "# Description of the boxplot data (assumed values based on the image and question)\n",
    "# Boxplot interpretation:\n",
    "q1 = -20  # First quartile\n",
    "median = -10  # Median\n",
    "q3 = 0  # Third quartile\n",
    "min_value = -40  # Minimum value\n",
    "max_value = 40  # Maximum value\n",
    "\n",
    "# Statements from the question:\n",
    "statements = [\n",
    "    \"More than half of the students in the sample had a negative difference in scores.\",\n",
    "    \"More than 20% of the students in the sample had a positive difference in scores.\",\n",
    "    \"At least one student in the sample had a difference higher than 40 points in scores.\",\n",
    "    \"60% of the students in the sample had a positive difference in scores.\",\n",
    "    \"No student in the sample had a difference in scores higher than 50 points.\"\n",
    "]\n",
    "\n",
    "# Analyze the statements:\n",
    "# 1. True: More than half had a negative difference since the median is -10.\n",
    "# 2. True: The third quartile is 0, meaning at least 25% had positive differences.\n",
    "# 3. True: The maximum value of 40 suggests someone could have exactly 40.\n",
    "# 4. False: Only 25% (not 60%) of the students had a positive difference.\n",
    "# 5. True: The maximum value is 40, so no score is above 50.\n",
    "\n",
    "# Incorrect statement:\n",
    "incorrect_statement = statements[3]\n",
    "\n",
    "# Output\n",
    "print(\"The incorrect statement is:\")\n",
    "print(incorrect_statement)\n",
    "\n",
    "# (Optional) Visualize the boxplot based on the assumed data\n",
    "data = [min_value, q1, median, q3, max_value]\n",
    "plt.boxplot(data, vert=False, patch_artist=True)\n",
    "plt.title(\"Boxplot of Score Differences\")\n",
    "plt.xlabel(\"Difference in Scores\")\n",
    "plt.show()"
   ],
   "id": "33648e0b65b3fb23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### bootstrap confidence intervals to assess the significance of the null hypothesis (H_0: \\mu = 0) based on resampling.",
   "id": "b247b2faf422792"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(27)\n",
    "# Simulated bootstrap results from the R code provided\n",
    "bootstrap_means = np.array([-6.54, -1.21])  # 90% CI\n",
    "bootstrap_means_95 = np.array([-7.05, -0.77])  # 95% CI\n",
    "bootstrap_means_99 = np.array([-8.09, 0.23])  # 99% CI\n",
    "\n",
    "# Analyzing significance levels:\n",
    "# 1. Alpha = 0.10 (90% CI): Does the interval contain 0?\n",
    "alpha_10_contains_zero = 0 >= bootstrap_means[0] and 0 <= bootstrap_means[1]\n",
    "\n",
    "# 2. Alpha = 0.025 (95% CI): Does the interval contain 0?\n",
    "alpha_025_contains_zero = 0 >= bootstrap_means_95[0] and 0 <= bootstrap_means_95[1]\n",
    "\n",
    "# 3. Alpha = 0.005 (99% CI): Does the interval contain 0?\n",
    "alpha_005_contains_zero = 0 >= bootstrap_means_99[0] and 0 <= bootstrap_means_99[1]\n",
    "\n",
    "# Determine the correct statement:\n",
    "if not alpha_10_contains_zero:\n",
    "    result = \"Significant at alpha = 0.1\"\n",
    "elif not alpha_025_contains_zero:\n",
    "    result = \"Significant at alpha = 0.025\"\n",
    "elif not alpha_005_contains_zero:\n",
    "    result = \"Significant at alpha = 0.01\"\n",
    "else:\n",
    "    result = \"No significant difference detected.\"\n",
    "\n",
    "print(\"Conclusion based on the confidence intervals:\")\n",
    "print(result)\n",
    "#option 1 i correct"
   ],
   "id": "b448e8fdbb45f389",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### bootstrap confidence intervals to evaluate whether the difference in means between two groups is statistically significant.",
   "id": "78ed49989cc9a88c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(28)\n",
    "# Corrected Python code to ensure the proper logic aligns with Option 4.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Simulated confidence intervals from R output\n",
    "ci_xlow = [-9.23, -2.94]  # CI for low scoring group\n",
    "ci_xhigh = [-3.11, 1.92]  # CI for high scoring group\n",
    "ci_diff = [1.41, 9.56]  # CI for difference in means\n",
    "\n",
    "# Determine if zero is included in the confidence intervals\n",
    "xlow_contains_zero = 0 >= ci_xlow[0] and 0 <= ci_xlow[1]\n",
    "xhigh_contains_zero = 0 >= ci_xhigh[0] and 0 <= ci_xhigh[1]\n",
    "diff_contains_zero = 0 >= ci_diff[0] and 0 <= ci_diff[1]\n",
    "\n",
    "# Analyze the significance\n",
    "if not diff_contains_zero:\n",
    "    result = \"A significant difference between the two groups is detected since the confidence interval for the difference in mean doesn’t include zero.\"\n",
    "else:\n",
    "    result = \"No significant difference between the two groups is detected because the confidence interval for the difference includes zero.\"\n",
    "\n",
    "# Print the corrected conclusion\n",
    "print(\"Conclusion (Corrected):\")\n",
    "print(result)\n",
    "\n",
    "# Correct Answer Based on Analysis\n",
    "correct_answer = 4\n",
    "print(f\"The correct answer is Option {correct_answer}.\")"
   ],
   "id": "ce3977b569b4609e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Poisson distribution",
   "id": "f8a8603c323a6db0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(29)\n",
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Given data\n",
    "lambda_ = 4  # average number of raisins\n",
    "k = 0        # no raisins\n",
    "\n",
    "# Calculate the probability\n",
    "probability = poisson.pmf(k, lambda_)\n",
    "print(f\"The probability that Karl's portion contains no raisins is: {probability:.3f}\")\n",
    "\n",
    "# Correct answer (closest option)\n",
    "if abs(probability - 0.018) < 1e-3:\n",
    "    correct_option = 2\n",
    "elif abs(probability - 0.001) < 1e-3:\n",
    "    correct_option = 1\n",
    "elif abs(probability - 0.183) < 1e-3:\n",
    "    correct_option = 3\n",
    "elif abs(probability - 0.250) < 1e-3:\n",
    "    correct_option = 4\n",
    "elif abs(probability - 0.368) < 1e-3:\n",
    "    correct_option = 5\n",
    "\n",
    "print(f\"The correct answer is Option {correct_option}.\")"
   ],
   "id": "e872d9c95824cb97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Poisson distribution",
   "id": "d5d51732d1abdd4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#(30)\n",
    "# Given data\n",
    "lambda_karoline = 8  # Average number of raisins for Karoline\n",
    "k = 4                # Upper limit for P(X <= 4)\n",
    "\n",
    "# Calculate P(X <= 4) and complement\n",
    "p_less_than_5 = poisson.cdf(k, lambda_karoline)\n",
    "p_greater_or_equal_5 = 1 - p_less_than_5\n",
    "\n",
    "print(f\"The probability that Karoline's portion contains five or more raisins is: {p_greater_or_equal_5:.3f}\")\n",
    "\n",
    "# Correct answer (closest option)\n",
    "if abs(p_greater_or_equal_5 - 0.092) < 1e-3:\n",
    "    correct_option = 1\n",
    "elif abs(p_greater_or_equal_5 - 0.099) < 1e-3:\n",
    "    correct_option = 2\n",
    "elif abs(p_greater_or_equal_5 - 0.191) < 1e-3:\n",
    "    correct_option = 3\n",
    "elif abs(p_greater_or_equal_5 - 0.809) < 1e-3:\n",
    "    correct_option = 4\n",
    "elif abs(p_greater_or_equal_5 - 0.900) < 1e-3:\n",
    "    correct_option = 5\n",
    "\n",
    "print(f\"The correct answer is Option {correct_option}.\")"
   ],
   "id": "ecd4d3aeb68220b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2024 may",
   "id": "1c811596c604bcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### confidence interval and hypothesis test ",
   "id": "a7e05051c3054872"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Problem parameters\n",
    "sample_mean = 17  # Observed sample mean\n",
    "pop_mean = 18       # Hypothesized population mean\n",
    "std_dev = 4.5       # Observed sample standard deviation\n",
    "n = 48               # Sample size\n",
    "df = n - 1           # Degrees of freedom\n",
    "\n",
    "# Calculate the t-statistic\n",
    "t_stat = (sample_mean - pop_mean) / (std_dev / (n ** 0.5))\n",
    "\n",
    "# Critical t-values for significance levels\n",
    "critical_t_5 = stats.t.ppf(1 - 0.05 / 2, df)  # Two-tailed 5%\n",
    "critical_t_10 = stats.t.ppf(1 - 0.10 / 2, df)  # Two-tailed 10%\n",
    "\n",
    "# Print t-statistic and critical values\n",
    "print(f\"T-statistic: {t_stat:.3f}\")\n",
    "print(f\"Critical t-value at 5% (two-tailed): ±{critical_t_5:.3f}\")\n",
    "print(f\"Critical t-value at 10% (two-tailed): ±{critical_t_10:.3f}\")\n",
    "\n",
    "# Conclusion based on t-statistic\n",
    "if abs(t_stat) > critical_t_10:\n",
    "    conclusion = \"Rejected at 10%\"\n",
    "else:\n",
    "    conclusion = \"Accepted at 10%\"\n",
    "\n",
    "if abs(t_stat) > critical_t_5:\n",
    "    conclusion_5 = \"Rejected at 5%\"\n",
    "else:\n",
    "    conclusion_5 = \"Accepted at 5%\"\n",
    "\n",
    "print(f\"Conclusion at 5%: {conclusion_5}\")\n",
    "print(f\"Conclusion at 10%: {conclusion}\")\n",
    "\n",
    "# Correct answer based on the solution\n",
    "correct_answer = \"Option 5: Rejected at 10%\"\n",
    "print(f\"Correct Answer: {correct_answer}\")"
   ],
   "id": "56bf2edff5bfa9b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### p-value ",
   "id": "c36144040d8d4521"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(2 * stats.t.sf(np.abs(-1.74), 45))\n",
   "id": "c607e957f8328209",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### confidence interval for std",
   "id": "b33af356113f3874"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_std = 0.09   # Sample standard deviation\n",
    "sample_size = 30     # Sample size\n",
    "confidence_level = 0.95     # Confidence level\n",
    "\n",
    "df = sample_size - 1\n",
    "\n",
    "# Alpha\n",
    "alpha = 1 - confidence_level\n",
    "\n",
    "# Chi-square critical values\n",
    "chi2_lower = stats.chi2.ppf(alpha / 2, df)\n",
    "chi2_upper = stats.chi2.ppf(1 - alpha / 2, df)\n",
    "\n",
    "# Confidence interval bounds\n",
    "lower_bound = np.sqrt((df * sample_std**2) / chi2_upper)\n",
    "upper_bound = np.sqrt((df * sample_std**2) / chi2_lower)\n",
    "\n",
    "print(\"[\" , lower_bound , \";\" ,  upper_bound , \"]\")"
   ],
   "id": "427f6180ec696e67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### probability P(X<3) for 5 given points of probability mass function",
   "id": "5bfb88225265762"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(0.17+0.22+0.28)",
   "id": "394ecb5e1aa53126",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculating the Variance of a Discrete Random Variable",
   "id": "3c7bf430ae263dd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Values of X and their probabilities\n",
    "x_values = np.array([0, 1, 2, 3, 4])\n",
    "probabilities = np.array([0.17, 0.22, 0.28, 0, 0.33])\n",
    "mean = 2.10  # Provided mean of X\n",
    "\n",
    "# Variance calculation\n",
    "variance = np.sum(probabilities * (x_values - mean)**2)\n",
    "\n",
    "print(f\"The variance of X is: {variance:.2f}\")"
   ],
   "id": "549cf218fc796688",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f0b59cbb95a028eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### effect of a group in one-way anova when given avarage mean and mean for group",
   "id": "f24222d72200b941"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Data\n",
    "overall_mean = 252.5  # Overall mean\n",
    "location1_mean = 250.0  # Average concentration for Location 1\n",
    "\n",
    "# Calculate the effect of Location 1\n",
    "effect_location1 = location1_mean - overall_mean\n",
    "\n",
    "# Print the result\n",
    "print(\"The effect of Location 1 is:\", effect_location1)"
   ],
   "id": "1cee8c150a12b23f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### standard error deviation of one-way anova ",
   "id": "3dc0bea5c8e62f23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# total sum of squares SST (915.92) \n",
    "# location sum of squares SS(location) (480.00)\n",
    "# Given values\n",
    "SSE = 915.92 - 480.00  # Calculate SSE\n",
    "n = 16  # Total number of observations\n",
    "k = 4   # Number of groups\n",
    "\n",
    "# Degrees of freedom for error\n",
    "df_error = n - k\n",
    "\n",
    "# Estimate of the error standard deviation\n",
    "sigma_hat = np.sqrt(SSE / df_error)\n",
    "\n",
    "print(\"The estimate of the error standard deviation (σ̂) is:\", round(sigma_hat, 3))"
   ],
   "id": "91f8607f62d59176",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = np.array([0, 0, 2, 2, 4, 4, 6, 6, 8, 8, 12, 12])\n",
    "y = np.array([16, 116, 1170, 841, 2287, 2012, 2653, 3333, 4270, 3999, 5750, 5407])\n",
    "fit = smf.ols('y ~ x', data=pd.DataFrame({'x':x, 'y':y})).fit()\n",
    "print(fit.summary(slim=True))"
   ],
   "id": "929cc03de6a4d1e3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
